---
layout: post
title: 딥러닝 모델 성능 개선 방법
description: >
  2023.01.26 ~  아홉번째 게시글
tags: [hydejack]
---

# 딥러닝 모델 성능 개선 방법

### Dacon 의 여러가지 대회들을 그동안 구경하며 참여해보고 싶다는 생각이 들게 되었다. 그래서 미리 모델 성능 향상을 위한 방법들을 공부해보려고 한다. 이 문서는 딥러닝 모델의 성능을 끌어올릴 수 있는 방법을 담은 로드맵들을 정리해보았다.


# Variance / Bias Analysis

### 무턱대고 이 방법 저 방법을 시도하며 박치기를 하는 방식은 바람직하지 못하다. 평가 metric 을 보고 어떤 부분에서 개선을 해야할지 분석해야 한다.
### 평가 메트릭에는 여러가지가 있는데 어떤 평가 메트릭을 사용해야 하는지를 결정해야한다. 문제 상황에 맞는 적절한 평가 메트릭을 사용하여, 모델의 성능을 정확히 이해해야 한다.
### 평가 메트릭을 분석하는 방법 또한 여러가지가 있는데, Training Error 와 Validation Error 를 공부했다.
### 우선 Bias 와 Variance 를 알아야한다. 이 둘은 모델의 상태를 나타내는 척도 중 하나이다. Variance 는 높을수록 예측 값들이 흩어져있고, Bias 가 높을수록 예측 값들이 정답과 떨어져있다는 것을 의미한다.
### 이런 Variance 와 Bias 를 보는 방법이 Training Error 와 Validation Error 를 이용하는 것이다.

![Image Description](../assets/img/Variance_and_Bias_TrainingError.jpeg)
 
### 위 그래프의 왼쪽을 보면 Training Error 가 높다.. 이는 모델의 예측 값이 정답 값과 동떨어져 있다는 것을 의미한다. 즉, **모델의 Bias 가 높다는 뜻** 이다.
### 그래프의 오른쪽에는 Training Error 와 Validation Error 의 차이가 크게 나는 것을 확인할 수 있다. 이는 예측값들이 흩어져 있어 모델의 Variance 가 높다는 것을 의미한다.

### 이를 통해 알아낸 것을 바탕으로 모델의 성능을 어떻게 향상 시킬 수 있을까?

# Variance 가 높다면?
* More Data (1)
* Regularization (2)
* Model selection (3)
* Hyperparameter Tuning (4)

# Bias 가 높다면?
* Bigger Model
* Longer/Better Optimization (5)
* Model selection (3)
* Hyperparameter Tuning (4)

## 이제 각각의 방법에 대해 알아보자.

# (1) More Data

### 이 방법은 데이터의 양을 늘려 모델의 과적합을 피하는 방법이다.
### 일반적인 방법으로 더 많은 학습 데이터를 수집하는것은 현실적으로 어려움이 있기 때문에 주로 대회에서는 Data Augmentation 이라는 방법을 사용한다.
![Image Description](../assets/img/Data_Augmentation_Example.webp)
### 주로 이미지를 뒤집거나 잘라서 학습 데이터의 양을 늘려주는 방법을 사용한다. Pytorch 에서 Data Augmentation 을 위한 모듈을 제공하고 있어서, 편리하게 자신의 코드에 추가할 수 있다.

# (2) Regularization

### 앞서 모델의 Variance 가 높다는 것은 모델의 과적합을 의미한다고 했었다.
![Image Description](../assets/img/Under_and_Overfit.webp)
### 이를 방지하기 위해서 Weight 가 높은 값을 가지는 것을 방지할 필요가 있는데, 이를 위해 사용되는 방법이 바로 *정규화* 이다. 자세한 설명은 아래 블로그에 나와있다.
### *참고하면 좋은 글*

* <https://jeongwooyeol0106.tistory.com/26>
* <https://subinium.github.io/introduction-to-normalization/>

### 이외에도 정규화 기법의 일종으로 Drop out 기법이 있다.
### Drop out 기법은 임의로 특정 노드를 학습에 제외시켜 모델의 과적합을 방지한다.
![Image Description](../assets/img/Dropout.webp)
### *참고하면 좋은 글*
* <https://heytech.tistory.com/127>
* <https://wandb.ai/wandb_fc/korean/reports/—VmlldzoxNDI4NzEy>

# Model selection
